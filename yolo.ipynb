{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrjbrE+S75SLryzwRlIRVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniket-singh-01/SIH2k24/blob/main/yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s478tE_snC2w",
        "outputId": "91bf86e8-386c-4548-fd2e-10acc1304883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (584 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install opencv-python-headless numpy\n",
        "!apt-get install -y wget unzip\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWYFmruTnFlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOXaXM2OnFqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define paths\n",
        "image_dir = '/content/Aadhaar/'  # Directory where your images are stored\n",
        "annotation_dir = '/content/data/labels/'  # Directory where you want to save annotations\n",
        "\n",
        "# Ensure the annotation directory exists\n",
        "os.makedirs(annotation_dir, exist_ok=True)\n",
        "\n",
        "# Create dummy annotation files for the images\n",
        "for image_file in os.listdir(image_dir):\n",
        "    if image_file.endswith('.jpg'):\n",
        "        base_name = os.path.splitext(image_file)[0]  # Get base name without extension\n",
        "        annotation_file = os.path.join(annotation_dir, base_name + '.txt')  # Path for annotation file\n",
        "\n",
        "        # Write dummy annotation\n",
        "        with open(annotation_file, 'w') as f:\n",
        "            # Replace this with actual annotation data\n",
        "            # Format: <class_id> <x_center> <y_center> <width> <height>\n",
        "            # Placeholder values should be replaced with actual bounding box data\n",
        "            f.write('0 0.5 0.5 1.0 1.0\\n')  # Example dummy annotation (needs real data)\n"
      ],
      "metadata": {
        "id": "cs2hN_KCnFtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "image_dir = '/content/Aadhaar'\n",
        "train_file = '/content/data/train.txt'\n",
        "valid_file = '/content/data/valid.txt'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "# Create train.txt and valid.txt with image paths\n",
        "with open(train_file, 'w') as f_train, open(valid_file, 'w') as f_valid:\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        f_train.write(f'{image_path}\\n')\n",
        "        f_valid.write(f'{image_path}\\n')  # Assuming the same images are used for validation\n"
      ],
      "metadata": {
        "id": "i7vHySXNnFyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check contents of train.txt\n",
        "with open('/content/data/train.txt', 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Check contents of valid.txt\n",
        "with open('/content/data/valid.txt', 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SwVDDYu4QJg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file_content = \"\"\"\n",
        "classes= 1\n",
        "train  = data/train.txt\n",
        "valid  = data/valid.txt\n",
        "names  = data/obj.names\n",
        "backup = backup/\n",
        "\"\"\"\n",
        "with open('/content/data/aadhar.data', 'w') as f:\n",
        "    f.write(data_file_content)\n"
      ],
      "metadata": {
        "id": "D8rB9Qj7J1iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_file_content = \"aadhar_photo\"\n",
        "with open('/content/data/obj.names', 'w') as f:\n",
        "    f.write(names_file_content)\n"
      ],
      "metadata": {
        "id": "DSnh1VJxJ1nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhnPSERXNbM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def modify_yolo_cfg(cfg_path, output_path, num_classes):\n",
        "    with open(cfg_path, 'r') as f:\n",
        "        cfg = f.read()\n",
        "\n",
        "    # Update filters and classes in the cfg file\n",
        "    filters = (num_classes + 5) * 3\n",
        "    cfg = re.sub(r'filters=\\d+', f'filters={filters}', cfg)\n",
        "    cfg = re.sub(r'classes=\\d+', f'classes={num_classes}', cfg)\n",
        "\n",
        "    # Write the modified cfg to a new file\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(cfg)\n",
        "\n",
        "# Paths\n",
        "base_cfg_path = '/content/yolov3.cfg'\n",
        "modified_cfg_path = '/content/yolov3_custom.cfg'\n",
        "num_classes = 1\n",
        "\n",
        "modify_yolo_cfg(base_cfg_path, modified_cfg_path, num_classes)\n"
      ],
      "metadata": {
        "id": "yL6Nw8-JJ1rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/yolov3_custom.cfg', 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "u-Ykz_dVNj0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data/aadhar.data /content/darknet/data/\n",
        "!cp /content/data/obj.names /content/darknet/data/\n",
        "!cp /content/yolov3_custom.cfg /content/darknet/\n",
        "!cp /content/yolov3.weights /content/darknet/\n"
      ],
      "metadata": {
        "id": "hwWSHHSRRKKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pjreddie/darknet\n",
        "%cd darknet\n",
        "!make\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "62obypaxKMld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the paths in aadhar.data\n",
        "data_file_content = \"\"\"\n",
        "classes= 1\n",
        "train  = /content/darknet/data/train.txt\n",
        "valid  = /content/darknet/data/valid.txt\n",
        "names  = /content/darknet/data/obj.names\n",
        "backup = /content/darknet/backup/\n",
        "\"\"\"\n",
        "\n",
        "# Write the corrected paths to the aadhar.data file\n",
        "with open('/content/darknet/data/aadhar.data', 'w') as f:\n",
        "    f.write(data_file_content)\n"
      ],
      "metadata": {
        "id": "fLgT2oUnKM3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the files are correctly placed\n",
        "!cp /content/data/train.txt /content/darknet/data/\n",
        "!cp /content/data/valid.txt /content/darknet/data/\n",
        "!cp /content/data/obj.names /content/darknet/data/\n"
      ],
      "metadata": {
        "id": "rlpjLQT6Sym2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check contents of train.txt\n",
        "with open('/content/data/train.txt', 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Check contents of valid.txt\n",
        "with open('/content/data/valid.txt', 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mWtAwE1cOYti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data/aadhar.data /content/darknet/data/\n",
        "!cp /content/data/obj.names /content/darknet/data/\n",
        "!cp /content/yolov3_custom.cfg /content/darknet/\n",
        "!cp /content/yolov3.weights /content/darknet/\n"
      ],
      "metadata": {
        "id": "OxtC-a4mRyqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/darknet\n",
        "!./darknet detector train data/aadhar.data yolov3_custom.cfg yolov3.weights\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "06pPXhFrMBzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the content of aadhar.data\n",
        "with open('/content/darknet/data/aadhar.data', 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zAQRrcgrMXTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7j3WO1H4MXX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pdf_to_images(pdf_path, dpi=300):\n",
        "    \"\"\"\n",
        "    Convert PDF pages to images.\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "        dpi (int): Dots per inch for image quality.\n",
        "    Returns:\n",
        "        images (list): List of images converted from PDF.\n",
        "    \"\"\"\n",
        "    # Convert PDF pages to images with specified DPI\n",
        "    images = convert_from_path(pdf_path, dpi=dpi)\n",
        "    return images\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"\n",
        "    Preprocess the image for rectangle detection.\n",
        "    Args:\n",
        "        image (numpy array): Input image.\n",
        "    Returns:\n",
        "        thresh (numpy array): Thresholded binary image.\n",
        "    \"\"\"\n",
        "    # Convert to HSV color space for better color processing\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Use the V channel from HSV color space for thresholding\n",
        "    v_channel = hsv[:, :, 2]\n",
        "\n",
        "    # Apply Gaussian blur to smooth the V channel image\n",
        "    blurred = cv2.GaussianBlur(v_channel, (5, 5), 0)\n",
        "\n",
        "    # Apply adaptive thresholding to get a binary image\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "    # Display the thresholded image for debugging\n",
        "    plt.imshow(thresh, cmap='gray')\n",
        "    plt.title('Thresholded Image')\n",
        "    plt.show()\n",
        "\n",
        "    return thresh\n",
        "\n",
        "def find_rectangles(thresh):\n",
        "    \"\"\"\n",
        "    Find rectangular contours in the thresholded image.\n",
        "    Args:\n",
        "        thresh (numpy array): Thresholded binary image.\n",
        "    Returns:\n",
        "        rectangles (list): List of detected rectangles as (x, y, w, h).\n",
        "    \"\"\"\n",
        "    # Find contours in the thresholded image\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    rectangles = []\n",
        "\n",
        "    for contour in contours:\n",
        "        # Approximate the contour to a polygon\n",
        "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "        if len(approx) == 4:  # Check if the contour is rectangular\n",
        "            (x, y, w, h) = cv2.boundingRect(approx)\n",
        "            aspect_ratio = w / float(h)\n",
        "\n",
        "            # Filter based on aspect ratio to find rectangular areas\n",
        "            if 1.2 < aspect_ratio < 2.0:  # Adjust aspect ratio based on your needs\n",
        "                rectangles.append((x, y, w, h))\n",
        "\n",
        "    # Print detected rectangles for debugging\n",
        "    print(f\"Detected rectangles: {rectangles}\")\n",
        "\n",
        "    return rectangles\n",
        "\n",
        "def save_single_extracted_image(image, rectangles, img_index):\n",
        "    \"\"\"\n",
        "    Save a single extracted image from detected rectangles.\n",
        "    Args:\n",
        "        image (numpy array): Input image.\n",
        "        rectangles (list): List of rectangles to extract.\n",
        "        img_index (int): Index of the image for naming purposes.\n",
        "    \"\"\"\n",
        "    if not rectangles:\n",
        "        print(\"No rectangles found to extract.\")\n",
        "        return\n",
        "\n",
        "    # Select the largest rectangle by area\n",
        "    largest_rectangle = max(rectangles, key=lambda rect: rect[2] * rect[3])\n",
        "    x, y, w, h = largest_rectangle\n",
        "\n",
        "    # Crop the detected object\n",
        "    extracted_image = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Save the cropped image\n",
        "    output_image_path = f'/content/extracted_image_{img_index}.jpg'\n",
        "    cv2.imwrite(output_image_path, extracted_image)\n",
        "    print(f\"Saved extracted image to {output_image_path}\")\n",
        "\n",
        "    # Display the extracted image for debugging\n",
        "    plt.imshow(cv2.cvtColor(extracted_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Extracted Image {img_index}')\n",
        "    plt.show()\n",
        "\n",
        "# Convert PDF to images\n",
        "pdf_path = \"/content/Masked_Aadhaar.pdf\"\n",
        "images = pdf_to_images(pdf_path, dpi=300)  # Increase DPI for better image quality\n",
        "\n",
        "# Process the first image (index 0) for demonstration\n",
        "img_index = 0\n",
        "img_np = np.array(images[img_index])\n",
        "\n",
        "# Check image dimensions and color channels for debugging\n",
        "print(f\"Processing image {img_index}: shape {img_np.shape}\")\n",
        "\n",
        "preprocessed_img = preprocess_image(img_np)\n",
        "rectangles = find_rectangles(preprocessed_img)\n",
        "\n",
        "# Save the most appropriate extracted image\n",
        "save_single_extracted_image(img_np, rectangles, img_index)\n"
      ],
      "metadata": {
        "id": "wjfFE8xXMXcI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}